\documentclass[11pt,nocut]{article}

\usepackage{../latex_style/packages}
\usepackage{../latex_style/notations}
\usepackage{ulem}

\title{\vspace{-2.0cm}%
	Optimization and Computational Linear Algebra for Data Science\\
Common mistakes}
%\author{LÃ©o \textsc{Miolane} \ $\cdot$ \ \texttt{leo.miolane@gmail.com}}
\date{}

\begin{document}
\maketitle

\begin{center}
\textbf{Warning}: the statements in {\color{red}{red}} below are all wrong!
\end{center}
\vspace{2mm}

\paragraph{Notations.} Let $x \in \R^n$ and $A,B \in \R^{n \times n}$.
{\color{red}
	$$
	Ax = \Im(A), \ \ \Im(A) + \Ker(A) = n, \ \ \Ker(A) = 0.
	$$
}
The correct formulation would be $
Ax \in \Im(A), \ \ \dim(\Im(A)) + \dim(\Ker(A)) = n, \ \ \Ker(A) = \{0\}.
$
\paragraph{Matrix multiplication \#1.}
$$
{\color{red}
	\text{If} \ \
	A = 
	\begin{pmatrix}
		a_{1,1} & \cdots & a_{1,m} \\
		\vdots & & \vdots \\
		a_{n,1} & \cdots & a_{n,m}
	\end{pmatrix},
	\ \ \text{then} \ \
	A^2
	=
	\begin{pmatrix}
		a_{1,1}^2 & \cdots & a_{1,m}^2 \\
		\vdots & & \vdots \\
		a_{n,1}^2 & \cdots & a_{n,m}^2
	\end{pmatrix}.
}
$$

\paragraph{Matrix multiplication \#2.}
Let $A,B \in \R^{n \times n}$.
{\color{red}
	$$
	\text{If} \ \ AB=0 \ \ \text{then} \ \ A=0 \ \ \text{or} \ \ B=0.
	$$
}

This property (which is true when $A,B$ are numbers) does not hold for matrices. Compute for instance
$$
\begin{pmatrix}
	0 & 1 \\
	0 & 0 
\end{pmatrix}
\begin{pmatrix}
	0 & 1 \\
	0 & 0 
\end{pmatrix}
=
\begin{pmatrix}
	0 & 0 \\
	0 & 0 
\end{pmatrix}.
$$
\paragraph{Simplifications.}
Let $A \in \R^{k \times n}$ and $x,u \in \R^n$. Suppose that $Ax=Au$ and that $A \neq 0$ ($A$ is not the all-zero matrix).
{\color{red}
	$$
	\text{Since} \ \ Ax=Au \ \ \text{one can simplify by $A$:} \ \ \xout{A} x = \xout{A} u \ \ \text{to get} \ \ x=u.
	$$
}
This is false when $\Ker(A) \neq \{0\}$: take $u=0$ and $x$ a non-zero vector in $\Ker(A)$. If $\Ker(A) = \{0\}$, the right way to justify that $x=u$ is the following. $Ax = Au$ implies that $A(x-u) = 0$. Hence $x-u \in \Ker(A) = \{0\}$: $x=u$.

In the case where $k=n$ and $A$ invertible, then one could simply multiply the equation $Ax = Au$ by $A^{-1}$ on both sides to get that $x=u$.

\paragraph{Expanding the Euclidean norm.}
Let $u,v \in \R^n$
{\color{red}
	$$
	\|u+v\|^2 = \|u\|^2 + 2 \|u\| \|v\| + \|v\|^2,
	$$
	or
	$$
	\|u+v\|^2 = u^2 + 2 u v + v^2.
	$$
}
The first formula is not correct, while the second has no meaning (what does $u^2$ or $uv$ mean when $u,v$ are vectors?). The right formula is
$$
\|u+v\|^2 = \|u\|^2 + 2 \langle u , v\rangle + \|v\|^2,
$$
where $\langle u,v \rangle$ is the dot product between $u$ and $v$.

\paragraph{Invertible matrices.} Let $A$ be a $n \times m$ matrix such that $\Ker(A) = \{0\}$.
{\color{red}
	$$
	\text{Since} \ \ \Ker(A) = \{0\}, \ \ A \ \text{is invertible and} \ \ \Im(A) = \R^n. 
	$$
}
This is only true in the case where $n=m$. Otherwise this makes no sense: an invertible matrix is \textbf{by definition a square matrix}. Moreover by the rank-nullity theorem $\dim (\Im(A)) = m - 0 = m$, which can be strictly less than $n$.

\paragraph{Matrix products.} Let $M$ be a symmetric matrix. By the spectral theorem there exists a diagonal matrix $D$ and an orthogonal matrix $P$ such that $M = P D P^{\sT}$. Then we have
{\color{red}
	$$
	M = P D P^{\sT} = P P^{\sT} D,
	$$
	and
	$$
	M^{2019} = P^{2019} D^{2019} (P^{\sT})^{2019}.
	$$
}
The first formula is false since for matrices $A,B$, $AB\neq BA$ in general. For the second, $(AB)^k = ABAB \dots AB \neq A^k B^k$ in general, since $AB$ may be different from $BA$.





\vspace{1cm}
\centerline{\pgfornament[width=7cm]{71}}

%\bibliographystyle{plain}
%\bibliography{./references.bib}
\end{document}
